{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kqAmL9YhiIVG"
      },
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "# import os\n",
        "\n",
        "# def unzip_folder(zip_path, extract_to):\n",
        "#     \"\"\"\n",
        "#     Unzip a zip archive to a specified directory.\n",
        "\n",
        "#     Parameters:\n",
        "#         zip_path (str): Path to the zip archive.\n",
        "#         extract_to (str): Directory where the contents will be extracted.\n",
        "\n",
        "#     Returns:\n",
        "#         None\n",
        "#     \"\"\"\n",
        "#     with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "#         zip_ref.extractall(extract_to)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Specify the path to the zip archive and the directory to extract to\n",
        "#     zip_path = '/content/plus.zip'\n",
        "#     extract_to = '/content'\n",
        "\n",
        "#     # Create the extract directory if it doesn't exist\n",
        "#     os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "#     # Unzip the folder\n",
        "#     unzip_folder(zip_path, extract_to)\n",
        "\n",
        "#     print(f\"Successfully extracted contents to: {extract_to}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "60YGxAmCx76D"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-pW-g9Fh-Px",
        "outputId": "d0538a91-763f-4d78-92f8-396af41908df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training images shape: (8000, 100, 100, 3)\n",
            "Training coordinates shape: (8000, 2)\n",
            "Test images shape: (2000, 100, 100, 3)\n",
            "Test coordinates shape: (2000, 2)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Path to the dataset folder\n",
        "# dataset_path = '/Users/dvirani/dp/dataset/'\n",
        "\n",
        "# Load annotations (image filenames and coordinates) from CSV\n",
        "annotations_file = pd.read_csv(f'/content/plus/plus_sign_coordinates.csv')\n",
        "\n",
        "# Prepare lists to store images and corresponding coordinates\n",
        "images = []\n",
        "coordinates = []\n",
        "\n",
        "# Loop through each row in the annotations file\n",
        "for idx, row in annotations_file.iterrows():\n",
        "    # Read and preprocess image\n",
        "    image_path = f'/content/plus/images/plus_sign_{idx}.png'\n",
        "    image = cv2.imread(image_path)  # Load image using OpenCV\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "\n",
        "    # Extract coordinates of the red dot\n",
        "    x, y = row['x'], row['y']\n",
        "\n",
        "    # Store image and coordinates\n",
        "    images.append(image)\n",
        "    coordinates.append((x, y))\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "images = np.array(images)\n",
        "coordinates = np.array(coordinates)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, coordinates, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize pixel values (optional preprocessing)\n",
        "X_train = X_train / 255.0  # Scale pixel values to [0, 1]\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Display shapes of the datasets\n",
        "print(f\"Training images shape: {X_train.shape}\")\n",
        "print(f\"Training coordinates shape: {y_train.shape}\")\n",
        "print(f\"Test images shape: {X_test.shape}\")\n",
        "print(f\"Test coordinates shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cpYKog1Wm6Vp"
      },
      "outputs": [],
      "source": [
        "max_train=y_train.max()\n",
        "max_test=y_test.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IhxHixUVnI0K"
      },
      "outputs": [],
      "source": [
        "# Normalize coordinates\n",
        "y_train_norm = y_train / max_train  # Replace max_value with the appropriate normalization factor\n",
        "y_val_norm = y_test / max_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IpbQ7wrRnVz5"
      },
      "outputs": [],
      "source": [
        "y_train=y_train_norm\n",
        "y_test=y_val_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaTJWh1EzI_p",
        "outputId": "b93f1e3a-41dc-4f4c-ade7-3448e7af467a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 100, 3)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8sEE9Xmh-Pz",
        "outputId": "eefdbfd9-8b3f-412b-976f-bb76c0daee7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 100, 3)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])\n",
        "input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GchmSnezh-Pz",
        "outputId": "28e5bab7-c003-48a1-dee4-ad8a4984d639"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 98, 98, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 49, 49, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 47, 47, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 23, 23, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 21, 21, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 19, 19, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 9, 9, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 10368)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               1327232   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 8)                 264       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1572474 (6.00 MB)\n",
            "Trainable params: 1572474 (6.00 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# input_shape = (X_train.shape[0], X_train.shape[2], X_train.shape[3])\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define CNN model\n",
        "def create_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(32,activation='relu'),\n",
        "        layers.Dense(8,activation='relu'),\n",
        "        layers.Dense(2)  # Output layer for x and y coordinates (2 values)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mqRb7eq0nlcb"
      },
      "outputs": [],
      "source": [
        "# Compile the model with custom optimizer and learning rate\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='mse')\n",
        "# ###########    much better 0.33#########"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAOgBDTdocHB",
        "outputId": "486ab95b-7a81-4bcb-d08e-1ec457b0f24e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "225/225 [==============================] - 192s 853ms/step - loss: 3.6112e-04 - val_loss: 2.0939e-04\n",
            "Epoch 2/32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "225/225 [==============================] - 186s 828ms/step - loss: 3.8974e-04 - val_loss: 2.7644e-04\n",
            "Epoch 3/32\n",
            "225/225 [==============================] - 186s 826ms/step - loss: 3.4992e-04 - val_loss: 3.6415e-04\n",
            "Epoch 4/32\n",
            "225/225 [==============================] - 195s 869ms/step - loss: 2.1480e-04 - val_loss: 1.8677e-04\n",
            "Epoch 5/32\n",
            "225/225 [==============================] - 190s 845ms/step - loss: 2.6805e-04 - val_loss: 2.0716e-04\n",
            "Epoch 6/32\n",
            "225/225 [==============================] - 187s 832ms/step - loss: 2.0496e-04 - val_loss: 1.9423e-04\n",
            "Epoch 7/32\n",
            "225/225 [==============================] - 195s 866ms/step - loss: 2.3224e-04 - val_loss: 1.1236e-04\n",
            "Epoch 8/32\n",
            "225/225 [==============================] - 190s 845ms/step - loss: 1.6020e-04 - val_loss: 4.7185e-04\n",
            "Epoch 9/32\n",
            "225/225 [==============================] - 192s 853ms/step - loss: 1.7592e-04 - val_loss: 1.4197e-04\n",
            "Epoch 10/32\n",
            "225/225 [==============================] - 194s 862ms/step - loss: 1.5294e-04 - val_loss: 1.3172e-04\n",
            "Epoch 11/32\n",
            "225/225 [==============================] - 192s 854ms/step - loss: 7.8601e-04 - val_loss: 3.3908e-04\n",
            "Epoch 12/32\n",
            "225/225 [==============================] - 187s 830ms/step - loss: 1.4076e-04 - val_loss: 1.2194e-04\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Assuming you have defined and compiled your model (`model`) properly\n",
        "# X_train and y_train_norm are your training data\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True),\n",
        "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Split your training data into training and validation sets\n",
        "# Here, assuming you want to use 10% of the data for validation\n",
        "validation_split = 0.1\n",
        "split_index = int(len(X_train) * validation_split)\n",
        "X_val = X_train[-split_index:]\n",
        "y_val = y_train_norm[-split_index:]\n",
        "X_train = X_train[:-split_index]\n",
        "y_train = y_train_norm[:-split_index]\n",
        "\n",
        "# Train the model with callbacks\n",
        "history = model.fit(X_train, y_train, epochs=32, batch_size=32, validation_data=(X_val, y_val), callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "CNHj7ie1yTwX"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "model.save_weights('plus.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SUifbs8ymlo",
        "outputId": "c5549189-08b2-4f92-8268-394446e51c1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 98, 98, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 49, 49, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 47, 47, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 23, 23, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 21, 21, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 19, 19, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 9, 9, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 10368)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               1327232   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 8)                 264       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1572474 (6.00 MB)\n",
            "Trainable params: 1572474 (6.00 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary() #((3*3)*3)*32 + 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nYrpzSdypdh",
        "outputId": "4d306e72-039d-4f31-d9c0-708b26ffbd3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 15s 230ms/step\n",
            "Baseline Error (MAE): 1.70%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming model is already defined and trained\n",
        "model.load_weights('plus.h5')\n",
        "\n",
        "# Predict coordinates using the model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = np.mean(np.abs(y_pred - y_test))\n",
        "\n",
        "# Calculate baseline error based on a simple benchmark (e.g., mean or median of y_train)\n",
        "# Replace y_train_mean with the appropriate benchmark value\n",
        "y_train_mean = np.mean(y_train)  # Calculate mean of the training target coordinates\n",
        "\n",
        "# Calculate baseline error as a percentage of the benchmark\n",
        "baseline_error = (mae / np.mean(np.abs(y_test - y_train_mean))) * 100\n",
        "\n",
        "print(\"Baseline Error (MAE): %.2f%%\" % baseline_error)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_m9zkh_Tpd1l"
      },
      "outputs": [],
      "source": [
        "# # Adjust model architecture and hyperparameters\n",
        "# model = models.Sequential([\n",
        "#     layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "#     layers.MaxPooling2D((2, 2)),\n",
        "#     layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "#     layers.MaxPooling2D((2, 2)),\n",
        "#     layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "#     layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "#     layers.MaxPooling2D((2, 2)),\n",
        "#     layers.Flatten(),\n",
        "#     layers.Dense(256, activation='relu'),\n",
        "#     layers.Dense(128, activation='relu'),\n",
        "#     layers.Dense(64, activation='relu'),\n",
        "#     layers.Dense(2)  # Output layer for x and y coordinates (2 values)\n",
        "# ])\n",
        "\n",
        "# # Compile the model with a lower learning rate\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "# model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "# # Train the model with data augmentation\n",
        "# datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "#     rotation_range=20,\n",
        "#     width_shift_range=0.1,\n",
        "#     height_shift_range=0.1,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True,\n",
        "#     vertical_flip=True,\n",
        "#     fill_mode='nearest'\n",
        "# )\n",
        "\n",
        "# history = model.fit(datagen.flow(X_train, y_train_norm, batch_size=32),\n",
        "#                     epochs=50,\n",
        "#                     validation_data=(X_test, y_test))\n",
        "\n",
        "# # Evaluate the model\n",
        "# loss = model.evaluate(X_test, y_test)\n",
        "# print(f'Validation Loss: {loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQz-cSf63zHK"
      },
      "outputs": [],
      "source": [
        "# Assuming X_train and y_train are your image data and corresponding coordinates\n",
        "# model.fit(X_train, y_train, epochs=32, batch_size=16, validation_split=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jffwFqcOh-P0"
      },
      "outputs": [],
      "source": [
        "# # Assuming X_val and y_val are your validation image data and corresponding coordinates\n",
        "# loss = model.evaluate(X_test, y_test)\n",
        "# print(f'Validation Loss: {loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OUA-K9Jh-P0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
